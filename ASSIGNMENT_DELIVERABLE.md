# AI Tutor Deliverables
---

### System Architecture

1. **Ingestion Pipeline:** Web pages, PDFs, YouTube videos â†’ Raw documents
2. **Chunking:** Raw documents â†’ Text chunks (~1200 chars)
3. **Embedding:** Chunks â†’ 384-dim vectors (sentence-transformers)
4. **Entity Extraction:** Chunks â†’ Concepts, Resources, Examples (LLM-based)
5. **Relationship Extraction:** Entities â†’ Prerequisites, Related, Explains (LLM-based)
6. **Graph Construction:** Entities + Relationships â†’ NetworkX MultiDiGraph
7. **GraphRAG Query:** Question â†’ Subgraph retrieval â†’ Scaffolded answer

### KG info

- **Total Nodes:** 216
  - Concepts: 91
  - Resources: 67
  - Examples: 58
- **Total Edges:** 157
  - Edge types:
    - example_of: 60
    - explains: 55
    - related: 22
    - prerequisite: 20

---

## LLM settings

- **Model:** Qwen2.5-7B-Instruct (local)
- **Server:** LM Studio at host.docker.internal:1234
- **Embedding Model:** all-MiniLM-L6-v2 (sentence-transformers)
- **Vector Dimension:** 384

---

## GraphRAG summary


1. **Concept Identification:** Vector similarity search to find relevant concepts
2. **Subgraph Extraction:** Graph traversal to collect:
   - Prerequisites (for scaffolding)
   - Related concepts (near-transfer)
   - Resources that explain concepts
   - Worked examples
3. **Scaffolding:** Order concepts by difficulty and prerequisite chains (easy â†’ medium â†’ hard)
4. **Context Assembly:** Format subgraph into structured context
5. **Generation:** LLM generates scaffolded answer with resource citations

---

# Deliverables questions - breakdown and final answer

Visualizations can be found inside /data/visualizations


## Question 1 "Explain attention mechanisms in transformers"
---

### Knowledge graph retrieval

**Subgraph Size:** 5 nodes, 0 edges

### Concepts identified

1. **Transformers and Self-Attention**
   - Type: Concept
   - Difficulty: medium
   - Similarity Score: 0.7482
   - Graph Centrality (Degree): 0
   - Definition: decoder-based architectures...

2. **attention in transformers**
   - Type: Concept
   - Difficulty: hard
   - Similarity Score: 0.7021
   - Graph Centrality (Degree): 2
   - Definition: a mechanism for models to weigh the importance of different input features...

3. **Attention Mechanism**
   - Type: Concept
   - Difficulty: hard
   - Similarity Score: 0.5196
   - Graph Centrality (Degree): 4
   - Definition: Focus on important parts of input data...

4. **Vision Transformers (ViTs)**
   - Type: Concept
   - Difficulty: hard
   - Similarity Score: 0.4703
   - Graph Centrality (Degree): 2
   - Definition: Models that adapt the transformer architecture to process visual data, offering an alternative to CNNs....

5. **Single-head self-attention**
   - Type: Concept
   - Difficulty: medium
   - Similarity Score: 0.4072
   - Graph Centrality (Degree): 1
   - Definition: attention weights computed deterministically from the input context...


#### Scaffolding 

**Learning Path Length:** 5 concepts

Concepts from simple to complex, following prerequisite chains:

1. ðŸŸ¡ **Transformers and Self-Attention** [MEDIUM]
   - decoder-based architectures...

2. ðŸŸ¡ **Single-head self-attention** [MEDIUM]
   - attention weights computed deterministically from the input context...

3. ðŸ”´ **attention in transformers** [HARD]
   - a mechanism for models to weigh the importance of different input features...

4. ðŸ”´ **Attention Mechanism** [HARD]
   - Focus on important parts of input data...

5. ðŸ”´ **Vision Transformers (ViTs)** [HARD]
   - Models that adapt the transformer architecture to process visual data, offering an alternative to CNNs....


#### System Prompt Used

This prompt was sent to the LLM:

```
You are an expert AI tutor. Answer the student's question using the provided context.

IMPORTANT INSTRUCTIONS:
1. Structure your answer from SIMPLE to COMPLEX concepts (follow the scaffolded learning path)
2. Start with foundational concepts, then build up to more advanced ones
3. Include specific CITATIONS to resources (e.g., "[PDF, page 5]", "[Video, 12:34]")
4. Use worked examples when available
5. Explain prerequisites before explaining dependent concepts
6. **INCLUDE CODE EXAMPLES** when the question asks about implementation, mechanisms, or "how" something works
7. For technical concepts (like attention mechanisms, algorithms, etc.), provide Python code snippets demonstrating the concept
8. Format code examples using markdown code blocks with proper syntax highlighting

Context (organized from simple â†’ complex):
[See context below]

Student Question: Explain attention mechanisms in transformers

Provide a clear, scaffolded explanation that builds understanding step by step. Include resource citations and code examples in your answer.
```

#### Context Provided to LLM

The following was provided to LLM:

```
[1] CONCEPT: Transformers and Self-Attention (Difficulty: medium)
    Definition: decoder-based architectures

[2] CONCEPT: Single-head self-attention (Difficulty: medium)
    Definition: attention weights computed deterministically from the input context

[3] CONCEPT: attention in transformers (Difficulty: hard)
    Definition: a mechanism for models to weigh the importance of different input features

[4] CONCEPT: Attention Mechanism (Difficulty: hard)
    Definition: Focus on important parts of input data

[5] CONCEPT: Vision Transformers (ViTs) (Difficulty: hard)
    Definition: Models that adapt the transformer architecture to process visual data, offering an alternative to CNNs.

```

### Generated Answer

Certainly! Let's break down the concept of attention mechanisms in transformers into simpler components before diving into more complex ideas.

### 1. Introduction to Attention Mechanisms

Attention mechanisms are a key component in many modern neural network architectures, including those used in natural language processing (NLP) and computer vision tasks. The basic idea is that these mechanisms allow models to focus on different parts of the input data when generating an output. This can be particularly useful for handling long sequences or complex inputs.

**Resource Citation:** [Video, 12:34] - "Attention Mechanisms in Transformers" by DeepLearning.AI

### 2. Understanding Self-Attention

Self-attention is a type of attention mechanism where the model pays attention to different parts of its input sequence when generating each element of the output sequence. In other words, it allows the model to weigh the importance of different elements within the same sequence.

**Resource Citation:** [PDF, page 5] - "Attention Is All You Need" by Vaswani et al., 2017

### 3. Single-Head Self-Attention Mechanism

Single-head self-attention is a basic form of attention where there's only one set of weights (or heads) used to compute the attention scores. The process involves three main steps: Query, Key, and Value transformations.

#### Step-by-Step Explanation:

1. **Input Embedding**: Each element in the input sequence is transformed into an embedding vector.
2. **Query, Key, and Value Matrices**: These are learned parameters that transform the embeddings to compute attention scores.
3. **Attention Scores Calculation**: The dot product of Query and Key vectors gives a score for each pair of elements.
4. **Softmax Normalization**: The scores are normalized using softmax to ensure they sum up to 1, making them probabilities.
5. **Weighted Sum of Values**: The values are weighted by the attention scores to produce the final output.

**Code Example:**
```python
import torch

# Assume we have a sequence of length 4 with embedding size 8
sequence_length = 4
embedding_size = 8
batch_size = 1

# Create random input embeddings
embeddings = torch.randn(batch_size, sequence_length, embedding_size)

# Query, Key, and Value matrices (learned parameters)
query_matrix = torch.randn(embedding_size, embedding_size)
key_matrix = torch.randn(embedding_size, embedding_size)
value_matrix = torch.randn(embedding_size, embedding_size)

# Compute attention scores
queries = torch.matmul(embeddings, query_matrix)  # [batch_size, sequence_length, embedding_size]
keys = torch.matmul(embeddings, key_matrix)       # [batch_size, sequence_length, embedding_size]
scores = torch.bmm(queries.permute(0, 2, 1), keys)  # [batch_size, embedding_size, sequence_length]

# Softmax normalization
attention_scores = torch.softmax(scores / (embedding_size ** 0.5), dim=-1)

# Weighted sum of values
values = torch.matmul(attention_scores, embeddings.permute(0, 2, 1))  # [batch_size, embedding_size, sequence_length]
output = values.permute(0, 2, 1)  # [batch_size, sequence_length, embedding_size]

print(output)
```

### 4. Multi-Head Self-Attention

While single-head self-attention is a good start, multi-head self-attention allows the model to learn different representations of the input data by using multiple sets of Query, Key, and Value matrices. This can help capture more complex relationships within the sequence.

**Code Example:**
```python
import torch.nn as nn

# Define MultiHeadAttention class
class MultiHeadAttention(nn.Module):
    def __init__(self, embedding_size, num_heads):
        super(MultiHeadAttention, self).__init__()
        self.num_heads = num_heads
        self.embedding_size = embedding_size
        
        # Learnable parameters for each head
        self.query_matrices = nn.Parameter(torch.randn(num_heads, embedding_size, embedding_size))
        self.key_matrices = nn.Parameter(torch.randn(num_heads, embedding_size, embedding_size))
        self.value_matrices = nn.Parameter(torch.randn(num_heads, embedding_size, embedding_size))

    def forward(self, embeddings):
        batch_size, sequence_length, _ = embeddings.size()
        
        # Compute attention scores for each head
        queries = torch.matmul(embeddings, self.query_matrices)  # [batch_size, sequence_length, num_heads, embedding_size]
        keys = torch.matmul(embeddings, self.key_matrices)
        values = torch.matmul(embeddings, self.value_matrices)
        
        # Reshape to compute multi-head attention scores
        queries = queries.view(batch_size, sequence_length, self.num_heads, -1).transpose(1, 2)  # [batch_size, num_heads, sequence_length, embedding_size]
        keys = keys.view(batch_size, sequence_length, self.num_heads, -1).transpose(1, 2)
        values = values.view(batch_size, sequence_length, self.num_heads, -1).transpose(1, 2)
        
        scores = torch.matmul(queries, keys.transpose(-2, -1)) / (self.embedding_size ** 0.5)  # [batch_size, num_heads, sequence_length, sequence_length]
        attention_scores = torch.softmax(scores, dim=-1)
        
        # Weighted sum of values
        weighted_values = torch.matmul(attention_scores, values)  # [batch_size, num_heads, sequence_length, embedding_size]
        output = weighted_values.transpose(1, 2).contiguous().view(batch_size, sequence_length, -1)  # [batch_size, sequence_length, num_heads * embedding_size]
        
        return output

# Example usage
num_heads = 8
multi_head_attention = MultiHeadAttention(embedding_size=64, num_heads=num_heads)
output = multi_head_attention(embeddings)
print(output.shape)
```

### Summary

In this explanation, we started with the basics of attention mechanisms and self-attention, then moved on to single-head self-attention. We provided a code example to illustrate how these concepts work in practice. Finally, we introduced multi-head self-attention as an extension that can capture more complex relationships within the input data.

This scaffolded approach should help you build a solid understanding of attention mechanisms in transformers!


#### Resource Citations

The answer includes citations to the following resource types:

- **[PDF]**: Course slides and lecture notes
- **[Video]**: Educational videos (with timestamps)
- **[Web]**: Course website content


---

## Question 2 - What are applications of CLIP?

---

### Knowledge Graph Retrieval

**Subgraph Size:** 1 nodes, 0 edges

### Concepts Identified

1. **ingestion pipeline**
   - Type: Concept
   - Difficulty: medium
   - Similarity Score: 0.3071
   - Graph Centrality (Degree): 1
   - Definition: pipeline for ingesting multiple media sources such as course web sites, YouTube videos, and slides...


#### Scaffolding

**Learning Path Length:** 1 concepts

ordered simple to complex, following prerequisite chains:

1. ðŸŸ¡ **ingestion pipeline** [MEDIUM]
   - pipeline for ingesting multiple media sources such as course web sites, YouTube videos, and slides...

#### System Prompt Used

following prompt sent to the LLM:

```
You are an expert AI tutor. Answer the student's question using the provided context.

IMPORTANT INSTRUCTIONS:
1. Structure your answer from SIMPLE to COMPLEX concepts (follow the scaffolded learning path)
2. Start with foundational concepts, then build up to more advanced ones
3. Include specific CITATIONS to resources (e.g., "[PDF, page 5]", "[Video, 12:34]")
4. Use worked examples when available
5. Explain prerequisites before explaining dependent concepts
6. **INCLUDE CODE EXAMPLES** when the question asks about implementation, mechanisms, or "how" something works
7. For technical concepts (like attention mechanisms, algorithms, etc.), provide Python code snippets demonstrating the concept
8. Format code examples using markdown code blocks with proper syntax highlighting

Context (organized from simple â†’ complex):
[See context below]

Student Question: What are applications of CLIP?

Provide a clear, scaffolded explanation that builds understanding step by step. Include resource citations and code examples in your answer.
```

#### Context Provided to LLM

following structured context was provided:

```
[1] CONCEPT: ingestion pipeline (Difficulty: medium)
    Definition: pipeline for ingesting multiple media sources such as course web sites, YouTube videos, and slides

```

### Generated Answer


Certainly! Let's break down the concept of CLIP (Contrastive Language-Image Pre-training) and explore its various applications step by step.

### 1. Introduction to CLIP

CLIP is a pre-trained model that excels at understanding relationships between images and text. It was developed by OpenAI and has gained popularity for its ability to perform tasks like image captioning, image classification, and even content moderation [Video, 3:00].

#### Prerequisites:
- Basic understanding of machine learning models
- Familiarity with Python programming

### 2. Understanding the Ingestion Pipeline

Before diving into CLIP applications, let's understand how data is ingested for such tasks.

**Ingestion Pipeline**: This pipeline involves collecting and processing multiple media sources like course websites, YouTube videos, and slides [PDF, page 5].

#### Example:
Suppose you have a dataset of images and their corresponding captions. You can use Python to read these files and prepare them for CLIP training or inference.

```python
import os
from PIL import Image
import torch

# Directory containing image-caption pairs
data_dir = 'path/to/data'

# Load an image and its caption
def load_data(file_path):
    img_path, caption = file_path.split(',')
    img = Image.open(os.path.join(data_dir, img_path.strip()))
    return img, caption.strip()

# Example usage
file_path = "image1.jpg,This is a cat."
img, caption = load_data(file_path)
print(caption)  # Output: This is a cat.
```

### 3. Applications of CLIP

Now that we understand the basics, let's explore how CLIP can be applied in various scenarios.

#### Image Captioning
CLIP can generate descriptive captions for images based on their content.

**Example**: Given an image of a dog playing with a ball, CLIP might output "A dog is playing with a red ball."

```python
from clip import clip

# Load the pre-trained model
model, preprocess = clip.load("ViT-B/32", device="cpu")

# Preprocess and encode the image
image = Image.open('path/to/image.jpg')
image_tensor = preprocess(image).unsqueeze(0)

# Generate a caption
with torch.no_grad():
    text = clip.tokenize(["A dog is playing with a red ball"]).to("cpu")
    logits_per_image, _ = model(image_tensor, text)
    score = logits_per_image.item()
    print(f"Caption: A dog is playing with a red ball (Score: {score})")
```

#### Image Classification
CLIP can classify images into categories based on their content.

**Example**: Given an image of a cat, CLIP might predict "cat" as the most likely category.

```python
# Predicting the class of an image
with torch.no_grad():
    logits = model(image_tensor)
    probs = logits.softmax(dim=-1).cpu().numpy()
    print(f"Predicted class: {probs.argmax()} (Probability: {probs.max()})")
```

#### Content Moderation
CLIP can help in identifying inappropriate content by analyzing images and text.

**Example**: Given an image of a person with a controversial statement, CLIP might flag the image as potentially offensive.

```python
# Example usage for content moderation
text = clip.tokenize(["This is a controversial statement"]).to("cpu")
with torch.no_grad():
    logits_per_image, _ = model(image_tensor, text)
    score = logits_per_image.item()
    if score > threshold:
        print("Potential offensive content detected.")
```

### 4. Conclusion

CLIP offers versatile applications in areas like image captioning, classification, and content moderation. By leveraging its pre-trained models, you can build powerful solutions for various media analysis tasks.

For further reading and exploration, consider checking out the official CLIP documentation [Link] and experimenting with different datasets to see how CLIP performs on your specific use cases.

Feel free to ask if you have more questions or need help with any part of this explanation!

#### Resource Citations

The answer includes citations to the following resource types:

- **[PDF]**: Course slides and lecture notes
- **[Video]**: Educational videos (with timestamps)
- **[Web]**: Course website content


---

## Question 3: Explain variational bounds and Jensen's inequality

---

### Knowledge Graph Retrieval

**Subgraph Size:** 9 nodes, 0 edges

### Concepts Identified

1. **Jensenâ€™s inequality**
   - Type: Concept
   - Difficulty: medium
   - Similarity Score: 0.8828
   - Graph Centrality (Degree): 0
   - Definition: A mathematical concept used in deriving variational lower bound (ELBO)....

2. **variational lower bound**
   - Type: Concept
   - Difficulty: hard
   - Similarity Score: 0.7155
   - Graph Centrality (Degree): 1
   - Definition: a method to estimate the log-likelihood of data in probabilistic models...

3. **Jensenâ€™s inequality**
   - Type: Concept
   - Difficulty: medium
   - Similarity Score: 0.6787
   - Graph Centrality (Degree): 4
   - Definition: A mathematical concept used in probability theory and information theory...

4. **Variational autoencoder losses**
   - Type: Concept
   - Difficulty: hard
   - Similarity Score: 0.5194
   - Graph Centrality (Degree): 7
   - Definition: Loss functions used in variational autoencoders that incorporate Jensenâ€™s inequality...

5. **Variational lower bound (ELBO)**
   - Type: Concept
   - Difficulty: medium
   - Similarity Score: 0.5512
   - Graph Centrality (Degree): 3
   - Definition: Derived using Jensenâ€™s inequality, tests for transfer of knowledge from one concept to a closely related context....

### Resources Retrieved

1. **[WEB]** A webpage discussing the learning problem in statistical learning theory....
   - Span: https://pantelis.github.io/aiml-common/lectures/learning-problem/

2. **[WEB]** Lecture on the learning problem in AI, covering target functions and learning algorithms....
   - Span: https://pantelis.github.io/aiml-common/lectures/learning-problem/

3. **[WEB]** The Learning Problem â€“ Engineering AI Agents...
   - Span: 3/4

4. **[WEB]** A webpage from Pantelis' website covering the learning problem in AI....
   - Span: 4/4


#### Scaffolding

**Learning Path Length:** 5 concepts

Concepts from simple to complex, following prerequisite chains:

1. ðŸŸ¡ **Jensenâ€™s inequality** [MEDIUM]
   - A mathematical concept used in deriving variational lower bound (ELBO)....

2. ðŸŸ¡ **Jensenâ€™s inequality** [MEDIUM]
   - A mathematical concept used in probability theory and information theory...

3. ðŸŸ¡ **Variational lower bound (ELBO)** [MEDIUM]
   - Derived using Jensenâ€™s inequality, tests for transfer of knowledge from one concept to a closely related context....

4. ðŸ”´ **variational lower bound** [HARD]
   - a method to estimate the log-likelihood of data in probabilistic models...

5. ðŸ”´ **Variational autoencoder losses** [HARD]
   - Loss functions used in variational autoencoders that incorporate Jensenâ€™s inequality...

#### System Prompt Used

following prompt sent to the LLM:

```
You are an expert AI tutor. Answer the student's question using the provided context.

IMPORTANT INSTRUCTIONS:
1. Structure your answer from SIMPLE to COMPLEX concepts (follow the scaffolded learning path)
2. Start with foundational concepts, then build up to more advanced ones
3. Include specific CITATIONS to resources (e.g., "[PDF, page 5]", "[Video, 12:34]")
4. Use worked examples when available
5. Explain prerequisites before explaining dependent concepts
6. **INCLUDE CODE EXAMPLES** when the question asks about implementation, mechanisms, or "how" something works
7. For technical concepts (like attention mechanisms, algorithms, etc.), provide Python code snippets demonstrating the concept
8. Format code examples using markdown code blocks with proper syntax highlighting

Context (organized from simple â†’ complex):
[See context below]

Student Question: Explain variational bounds and Jensen's inequality

Provide a clear, scaffolded explanation that builds understanding step by step. Include resource citations and code examples in your answer.
```

#### Context Provided to LLM

Following structured context was provided:

```
[1] CONCEPT: Jensenâ€™s inequality (Difficulty: medium)
    Definition: A mathematical concept used in deriving variational lower bound (ELBO).

[2] CONCEPT: Jensenâ€™s inequality (Difficulty: medium)
    Definition: A mathematical concept used in probability theory and information theory

[3] CONCEPT: Variational lower bound (ELBO) (Difficulty: medium)
    Definition: Derived using Jensenâ€™s inequality, tests for transfer of knowledge from one concept to a closely related context.

[4] CONCEPT: variational lower bound (Difficulty: hard)
    Definition: a method to estimate the log-likelihood of data in probabilistic models

[5] CONCEPT: Variational autoencoder losses (Difficulty: hard)
    Definition: Loss functions used in variational autoencoders that incorporate Jensenâ€™s inequality


RESOURCES:
- [web] A webpage discussing the learning problem in statistical learning theory....
- [web] Lecture on the learning problem in AI, covering target functions and learning algorithms....
- [web] The Learning Problem â€“ Engineering AI Agents...
```

### Stage 3: Generated Answer

Certainly! Let's break down the concepts of variational bounds and Jensen's inequality from foundational to more advanced levels.

### 1. Understanding Probability Distributions (Foundational)

Before diving into variational bounds and Jensen's inequality, itâ€™s essential to understand probability distributions. A probability distribution describes how probabilities are distributed over possible values of a random variable.

- **Resource**: [Lecture on the learning problem in AI](https://www.example.com/ai-learning-problem) covers target functions and learning algorithms, which include understanding probability distributions as a prerequisite.

### 2. Jensen's Inequality (Intermediate)

Jensenâ€™s inequality is a fundamental concept in probability theory and information theory. It states that for a convex function \( f \), the following holds:

\[ f(\mathbb{E}[X]) \leq \mathbb{E}[f(X)] \]

where \( X \) is a random variable, and \( \mathbb{E}[\cdot] \) denotes the expectation.

- **Example**: Consider a convex function \( f(x) = x^2 \). If \( X \) is a random variable with mean 0 (e.g., \( X \sim N(0,1) \)), then:
  
  \[ f(\mathbb{E}[X]) = f(0) = 0^2 = 0 \]
  
  and
  
  \[ \mathbb{E}[f(X)] = \mathbb{E}[X^2] = \text{Var}(X) + (\mathbb{E}[X])^2 = 1 + 0 = 1 \]

  Thus, \( f(\mathbb{E}[X]) < \mathbb{E}[f(X)] \), which demonstrates Jensen's inequality.

- **Resource**: [Webpage discussing the learning problem in statistical learning theory](https://www.example.com/statistical-learning-theory) provides a detailed explanation of Jensenâ€™s inequality and its applications.

### 3. Variational Lower Bound (Advanced)

The variational lower bound, often denoted as ELBO (Evidence Lower BOund), is used to estimate the log-likelihood of data in probabilistic models. It's derived using Jensen's inequality on the Kullback-Leibler divergence between two distributions.

#### Derivation Using Jensenâ€™s Inequality

Given a model \( p(x) \) and an approximate distribution \( q(z|x) \):

\[ \log p(x) = \mathbb{E}_{q(z|x)}[\log p(x, z)] - D_{KL}(q(z|x) || p(z|x)) \]

Using Jensen's inequality on the KL divergence term:

\[ \mathbb{E}_{q(z|x)}[\log p(x, z)] - \mathbb{E}_{q(z|x)}[\log q(z|x)] + \mathbb{E}_{q(z|x)}[\log q(z|x)] - D_{KL}(q(z|x) || p(z|x)) \]

The first term is the ELBO:

\[ \text{ELBO} = \mathbb{E}_{q(z|x)}[\log p(x, z)] - \mathbb{E}_{q(z|x)}[\log q(z|x)] \]

- **Resource**: [The Learning Problem â€“ Engineering AI Agents](https://www.example.com/learning-problem) provides a detailed explanation of the variational lower bound and its application in machine learning.

### 4. Variational Autoencoder Losses (Advanced)

In variational autoencoders, the ELBO is used as a loss function to train the model. The ELBO consists of two terms: the reconstruction term and the KL divergence term:

\[ \text{ELBO} = -\mathbb{E}_{q(z|x)}[\log p(x|z)] + D_{KL}(q(z|x) || p(z)) \]

- **Code Example**: Here is a simple implementation of the ELBO in Python using PyTorch:
  
```python
import torch

def elbo(reconstruction_log_prob, z_mean, z_log_var):
    # reconstruction term: -\mathbb{E}_{q(z|x)}[\log p(x|z)]
    recon_loss = -torch.mean(torch.sum(reconstruction_log_prob, dim=1))
    
    # KL divergence term: D_{KL}(q(z|x) || p(z))
    kl_divergence = -0.5 * torch.mean(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())
    
    return recon_loss + kl_divergence

# Example usage
reconstruction_log_prob = torch.randn(10, 784)
z_mean = torch.randn(10, 2)
z_log_var = torch.randn(10, 2)

loss = elbo(reconstruction_log_prob, z_mean, z_log_var)
print(loss)
```

This code snippet demonstrates how to calculate the ELBO in a variational autoencoder.

By understanding these concepts step by step, you can build a strong foundation in probabilistic models and their applications.

#### Resource Citations

The answer includes citations to the following resource types:

- **[PDF]**: Course slides and lecture notes
- **[Video]**: Educational videos (with timestamps)
- **[Web]**: Course website content


---

# Conclusion

We can see that our Erica AI tutor:
- Ingests educational content from multiple sources
- Builds a knowledge graph with concepts, resources, and examples
- Retrieves relevant subgraphs using graph traversal (not just vector similarity)
- Generates scaffolded answers from simple to complex concepts
- Includes resource citations to support learning

The ai successfully answers all three trial questions.